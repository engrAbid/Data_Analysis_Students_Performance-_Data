# Step 1: Data Cleaning and Preprocessing  

Handling Missing Values  
One of the first challenges was dealing with missing or incomplete data. Empty cells and errors were scattered throughout the dataset, which could distort analysis results. To address this:  
I used Excel tools to locate blank cells efficiently.  
Missing values in critical columns were either filled with default values or estimated based on available data.  
Functions helped replace errors with meaningful placeholders.  

Correcting Spelling and Formatting Errors  
Inconsistent data entry was another major issue. For example:  
Gender entries varied between different formats which were standardized.  
Subject names had typos, which were corrected using Find and Replace.  
Extra spaces were removed, while name formatting was corrected.  

Standardizing Data Formats  
To maintain consistency:  
Dates were formatted uniformly.  
Numeric grades were adjusted to two decimal places.  
Combined fields were split into separate columns.  


# Step 2: Data Validation and Quality Checks  

Removing Duplicate Entries  
Duplicate records can lead to incorrect analysis.
Applied Remove Duplicates function.  
Used formulas to verify unique entries.  

Detecting and Correcting Outliers  
Some data points were unrealistic. To fix this:  
Conditional Formatting highlighted extreme values.  
Statistical functions helped identify anomalies.  

Formula-Based Calculations  
To enhance the datasets analytical value:  
Aggregate scores were computed.  
Performance categories were assigned using logical statements.  
